expense <- c(17,22,30,37,47,30.5,32.5,39,51.5,40)
machine_data <- data.frame(usage=usage, expense=expense)
machine_regression <- lm(expense ~ usage, machine_data)
summary(machine_regression)
log_density <- log(oddbooks$density)
oddbooks$area <- oddbooks$height * oddbooks$breadth
library(DAAG)
oddbooks$area <- oddbooks$height * oddbooks$breadth
oddbooks$volume <- oddbooks$thick * oddbooks$area
oddbooks$density <- oddbooks$weight / oddbooks$volume
log_weight <- log(oddbooks$weight)
log_volume <- log(oddbooks$volume)
plot(log_volume, log_weight)
weight_vs_volume <- lm(log(weight) ~ log(volume), oddbooks)
abline(a=-8.942, b=1.696)
summary(weight_vs_volume)
log_weight <- log(oddbooks$weight)
log_area <- log(oddbooks$area)
plot(log_area, log_weight)
weight_vs_area <- lm(log(weight) ~ log(area), oddbooks)
abline(a=1.697, b=0.793)
summary(weight_vs_area)
log_density <- log(oddbooks$density)
log_volume <- log(oddbooks$volume)
plot(log_volume, log_density)
density_vs_volume <- lm(log(density) ~ log(volume), oddbooks)
abline(a=-8.942, b=1.696) # edit this
summary(density_vs_volume)
log_area <- log(oddbooks$area)
plot(log_area, log_density)
density_vs_area <- lm(log(density) ~ log(area), oddbooks)
abline(a=1.697, b=0.793) # edit this
summary(density_vs_area)
log_density <- log(oddbooks$density)
log_volume <- log(oddbooks$volume)
plot(log_volume, log_density)
density_vs_volume <- lm(log(density) ~ log(volume), oddbooks)
abline(a=-8.942, b=0.696)
summary(density_vs_volume)
log_area <- log(oddbooks$area)
plot(log_area, log_density)
density_vs_area <- lm(log(density) ~ log(area), oddbooks)
abline(a=-5.109, b=0.419)
summary(density_vs_area)
heights <- c(68,64,62,65,66)
weights <- c(132,108,102,115,128)
swimmers <- data.frame(heights=heights, weights=weights)
plot(swimmers)
abline(a=-240.5, b=5.5)
swim_regression <- lm(weights ~ heights, swimmers)
summary(swim_regression)
plot(swim_regression)
oddbooks$area <- oddbooks$height * oddbooks$breadth
oddbooks$volume <- oddbooks$thick * oddbooks$area
oddbooks$density <- oddbooks$weight / oddbooks$volume
log_weight <- log(oddbooks$weight)
log_volume <- log(oddbooks$volume)
plot(log_volume, log_weight)
weight_vs_volume <- lm(log(weight) ~ log(volume), oddbooks)
abline(a=-8.942, b=1.696)
summary(weight_vs_volume)
log_weight <- log(oddbooks$weight)
log_area <- log(oddbooks$area)
plot(log_area, log_weight, main="log(weight) vs log(area)")
weight_vs_area <- lm(log(weight) ~ log(area), oddbooks)
abline(a=1.697, b=0.793)
summary(weight_vs_area)
det(cbind(c(1,-1,-1,-1),c(-1,1,-1,-1),c(-1,-1,1,-1),c(-1,-1,-1,1)))
curve(dchisq(x,1),ylab="")
curve(dnorm(x,1),ylab="")
curve(dgamma(x,1),ylab="")
curve(dbeta(x,1,1),ylab="")
curve(dt(x,1),ylab="")
integrate(x^3,0,1)
integrate(function(x) x^3,0,1)
4*integrate(function(x),0,1)
4*integrate(function(x) x^3,0,1)
4*integrate(function(x) x^3,0,1)$value
4*integrate(function(x) x^3,0,3/5)$value
4*integrate(function(x) x^3,0,2/3)$value
4*integrate(function(x) x^3,0,3/4)$value
4*integrate(function(x) x^3,0,4/5)$value
qexp(0.95)
A <- rbind(c(0,1),c(2,3))
eigen(A %*% t(A))
eigen(t(A) %*% A)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
bls_unemployment_data <- read.csv("rawdata/Unemployment by state 2020-2021.csv")[,c(1,2,3,4,11)]
# List of state names:
state_names <- bls_unemployment_data$State[1:53]
# Initialize empty matrix
unemployment_data <- data.frame(matrix(ncol=55,nrow=15))
# Label matrix with state names
colnames(unemployment_data) <- c("Year", "Month", state_names)
# Initialize dates
unemployment_data$Year <- c(rep(2020,12),rep(2021,3))
unemployment_data$Month <- c(1:12, 1:3)
# Fill in matrix with data from the BLS file
for (m in 1:15) {
for (s in 1:53) {
unemployment_data[m,s+2]<-bls_unemployment_data[s+53*(m-1),5]
}
}
# Save the cleaned data
write.csv(unemployment_data,"output/unemployment data.csv")
# Define helper functions to extract the year, month, and day of a COVID report:
year_num <- function(x) {
as.numeric(substr(x,1,4))
}
month_num <- function(x) {
as.numeric(substr(x,6,7))
}
day_num <- function(x) {
as.numeric(substr(x,9,10))
}
# Read dataset of daily COVID cases and deaths for each state
covid_by_state <- read.csv("rawdata/COVID cases by state.csv")[,c(1,2,3,6,8,11)]
# Parse date strings from the file
covid_by_state$submission_date <- as.Date(covid_by_state$submission_date, format = "%m/%d/%Y")
# Get the year, month, and day using the helper functions:
covid_by_state$year <- year_num(covid_by_state$submission_date)
covid_by_state$month <- month_num(covid_by_state$submission_date)
covid_by_state$day <- day_num(covid_by_state$submission_date)
# Sort dataframe by location and date
attach(covid_by_state)
covid_by_state <- covid_by_state[order(year, month, day, state),]
detach(covid_by_state)
covid_data <- covid_by_state %>%
group_by(state, year, month) %>%
summarize(cases=sum(new_case),deaths=sum(new_death))
# Copy the monthly unemployment data table:
cases_data <- unemployment_data[,1:2]
cases_data[16,] <- c(2021,4)
deaths_data <- unemployment_data[,1:2]
deaths_data[16,] <- c(2021,4)
# Fill in the monthly COVID case and deaths dataframes:
for (s in 1:60) {
cases_data[s+2] <- rep(0,16)
colnames(cases_data)[s+2] <- covid_data$state[1+16*(s-1)]
deaths_data[s+2] <- rep(0,16)
colnames(deaths_data)[s+2] <- covid_data$state[1+16*(s-1)]
for (m in 1:16) {
cases_data[m,s+2] <- covid_data[1+16*(s-1)+m,4]
deaths_data[m,s+2] <- covid_data[1+16*(s-1)+m,5]
}
}
cases_data <- cases_data[c(-16),c(-6,-14,-16,-31,-47,-48,-50,-57)]
deaths_data <- deaths_data[c(-16),c(-6,-14,-16,-31,-47,-48,-50,-57)]
unemployment_data <- unemployment_data[,c(-8)]
colnames(unemployment_data) <- c(
"Year","Month","AL","AK","AZ","AR","CA","CO","CT","DE","DC","FL","GA","HI",
"ID","IL","IN","IA","KS","KY","LA","ME","MD","MA","MI","MN","MS","MO","MT",
"NE","NV","NH","NJ","NM","NY","NYC","NC","ND","OH","OK","OR","PA","RI","SC",
"SD","TN","TX","UT","VT","VA","WA","WV","WI","WY"
)
unemployment_data <- unemployment_data[,
c(1,2,4,3,6,5,7:9,11,10,12:14,18,15:17,
19:21,24,23,22,25:26,28,27,29,37:38,
30,32,33:34,31,35,36,39:48,
50,49,51,53,52,54)
]
unemployment_changes <- unemployment_data
unemployment_changes[1:14,3:54] <- unemployment_changes[2:15,3:54] - unemployment_changes[1:14,3:54]
unemployment_changes <- unemployment_changes[c(-15),]
# for (i in 1:52) {
#   cases <- cases_data[1:14,i+2]
#   deaths <- deaths_data[1:14,i+2]
#   unemp_chg <- unemployment_changes[,i+2]
#   cases_vs_unemp <- lm(unemp_chg ~ cases)
#   deaths_vs_unemp <- lm(unemp_chg ~ deaths)
#   plot(cases,unemp_chg, main=paste(colnames(unemployment_changes)[i+2],"unemployment change vs cases"))
#   abline(cases_vs_unemp$coefficients[[1]],cases_vs_unemp$coefficients[[2]])
#   plot(deaths, unemp_chg, main=paste(colnames(unemployment_changes)[i+2],"unemployment change vs deaths"))
#   abline(deaths_vs_unemp$coefficients[[1]],deaths_vs_unemp$coefficients[[2]])
# }
cases <- numeric(14*52)
deaths <- numeric(14*52)
unemp <- numeric(14*52)
for (m in 1:14) {
for (s in 1:52) {
cases[s+52*(m-1)] <- cases_data[m,s+2]
deaths[s+52*(m-1)] <- deaths_data[m,s+2]
unemp[s+52*(m-1)] <- unemployment_changes[m,s+2]
}
}
# cases_vs_unemp <- lm(unemp ~ cases)
# summary(cases_vs_unemp)
# deaths_vs_unemp <- lm(unemp ~ deaths)
# summary(deaths_vs_unemp)
both_vs_unemp <- lm(unemp ~ cases + deaths)
summary(both_vs_unemp)
state_pops <- read.csv("output/State populations 2020.csv")[,-1]
# Delete New York City because it's not in the state population list
cases_per_capita <- cases_data[,-38]
deaths_per_capita <- deaths_data[,-38]
for (m in 1:15) {
for (s in 1:51) {
# divide cases_data and deaths_data columns by the pop of that state
cases_per_capita[m,s+2] <- cases_per_capita[m,s+2]/as.numeric(state_pops[2,s])
deaths_per_capita[m,s+2] <- deaths_per_capita[m,s+2]/as.numeric(state_pops[2,s])
}
}
cases <- numeric(14*51)
deaths <- numeric(14*51)
unemp <- numeric(14*51)
for (m in 1:14) {
for (s in 1:51) {
cases[s+51*(m-1)] <- cases_per_capita[m,s+2]
deaths[s+51*(m-1)] <- deaths_per_capita[m,s+2]
unemp[s+51*(m-1)] <- unemployment_changes[m,s+2]
}
}
# cases_vs_unemp <- lm(unemp ~ cases)
# summary(cases_vs_unemp)
# deaths_vs_unemp <- lm(unemp ~ deaths)
# summary(deaths_vs_unemp)
both_vs_unemp <- lm(unemp ~ cases + deaths)
summary(both_vs_unemp)
plot(both_vs_unemp)
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(pROC)
library(tree)
install.packages("rpart.plot"); install.packages("mlbench"); install.packages("tree")
library(mlbench)
library(caret)
library(lime)
library(e1071)
install.packages("lime")
library(dplyr)
library(ggplot2)
library(lubridate)
library(quantmod)
library(xts)
library(PerformanceAnalytics)
install.packages("quantmod")
library(dplyr)
library(ggplot2)
library(lubridate)
library(quantmod)
library(xts)
library(PerformanceAnalytics)
install.packages("PerformanceAnalytics")
library(dplyr)
library(ggplot2)
library(lubridate)
library(quantmod)
library(xts)
library(PerformanceAnalytics)
install.packages("rpart")
install.packages("rpart.plot")
install.packages("mlbench")
library(mlbench)
library(rpart)
library(rpart.plot)
library(mass)
library(MASS)
library(DAAG)
setwd("~/GitHub/math23c-rproject")
# This script shows the distributions of month-over-month price changes of our commodities.
library(eeptools) # to import the decomma() function
commodity_prices <- read.csv("source_data/commodities data.csv")
recession_dates <- read.csv("source_data/monthly recession indicator.csv")
recession_dates <- recession_dates[c(-242),] # Removed the entry for March 2021 so that the datasets have congruent date ranges.
commodity_prices[,9] <- decomma(commodity_prices[,9]) # Remove commas from the price of gold column.
goods <- c("Month","Crude_oil", "Sugar", "Soybeans", "Wheat", "Beef", "Rubber", "Cocoa_beans", "Gold", "USD_EUR", "Ice_cream", "Unemployment")
names(commodity_prices) <- goods
# Adding a column to distinguish the three different recessions in our date range.
recession_dates$which_recession <- recession_dates$USREC
recession_dates[84:101,3] <- 2*recession_dates[84:101,3]
recession_dates[230:241,3] <- 3*recession_dates[230:241,3]
# Find month-over-month price changes for each commodity
price_changes <- commodity_prices
for (c in 2:11) {
for (r in 2:241) {
price_changes[r,c] <- commodity_prices[r,c] / commodity_prices[r-1,c] - 1
}
}
price_changes$recession_bool <- recession_dates$USREC
price_changes$which_recession <- recession_dates$which_recession
price_changes <- price_changes[c(-1),]
write.csv(price_changes, "output_files/price changes.csv")
# Display a histogram of the price changes
for (i in 2:11) {
name <- goods[i]
hist(price_changes[,i], main=name)
}
# Repeating that, but during recessions only
for (i in 2:11) {
name <- paste(goods[i],"(recession)")
values <- price_changes[,c(i,13)]
values <- values[values[,2] == 1,]
hist(values[,1], main=name)
}
# Repeat for months not in recession
for (i in 2:11) {
name <- paste(goods[i],"(non-recession)")
values <- price_changes[,c(i,13)]
values <- values[values[,2] == 0,]
hist(values[,1], main=name)
}
library(boot)
library(caret)
price_changes <- read.csv("source_data/price changes.csv")
soybeans_regression <- glm(recession_bool ~ Soybeans, data = price_changes, family = 'binomial')
summary(soybeans_regression)
plot(price_changes$Soybeans, price_changes$recession_bool)
gold_regression <- glm(recession_bool ~ Gold, data = price_changes, family = 'binomial')
summary(gold_regression)
plot(price_changes$Gold, price_changes$recession_bool)
goods_vs_recession_logistic_model <- glm(
recession_bool ~ Crude_oil + Sugar + Soybeans + Wheat + Beef + Rubber + Cocoa_beans + Gold + USD_EUR + Ice_cream,
data = price_changes, family = 'binomial')
summary(goods_vs_recession_logistic_model)
negative_goods_regression <- glm(recession_bool ~ Crude_oil + Wheat + Rubber + Ice_cream, data = price_changes, family = 'binomial')
summary(negative_goods_regression)
# Probability of a recession if all of these goods lost 100% of their value this month:
inv.logit(-1.6582+0.2640+0.7643+0.8586+1.5616)
# Probability of a recession if all of these goods doubled in price last month:
inv.logit(-1.6582-0.2640-0.7643-0.8586-1.5616)
icecream_regression <- glm(recession_bool ~ Ice_cream, data = price_changes, family = 'binomial')
summary(icecream_regression)
plot(price_changes$Ice_cream, price_changes$recession_bool)
curve(inv.logit(-1.5900*x-1.6687), add=TRUE)
icecream_predictions <- as.factor(predict(icecream_regression, newdata=price_changes, type='response') > inv.logit(-1.6687))
confusionMatrix(icecream_predictions, reference = as.factor(price_changes$recession_bool==1))
recession_predictions <- as.factor(predict(goods_vs_recession_logistic_model, newdata=price_changes, type='response') > inv.logit(-1.7006))
confusionMatrix(recession_predictions, reference = as.factor(price_changes$recession_bool==1))
dlevy(1,2,3)
library(mlbench)
set.seed(234)
x <- c(1,2,4)
y <- c(5,9,11)
plot(x,y)
lm(y~x)
summary(lm(y~x))
summary(lm(2*y~x))
summary(lm((y+3)~x))
summary(lm(y ~ x1+x2))
x1 <- c(1,2,3)
x2 <- c(1.01,2.01,3.01)
y <- c(1,4,9)
summary(lm(y ~ x1+x2))
anova(lm(y ~ x1+x2))
x1 <- c(1,2,3)
x2 <- c(1.01,2.01,3.01)
y <- c(2,4,6)
summary(lm(y ~ x1+x2))
anova(lm(y ~ x1+x2))
x1 <- c(1.01,2,3)
x1 <- c(1.01,2,3)
x2 <- c(1.01,2.01,3)
y <- c(2,4,6)
summary(lm(y ~ x1+x2))
x1 <- c(1.01,2.01,3)
x2 <- c(1.01,2.01,3)
y <- c(2,4,6)
summary(lm(y ~ x1+x2))
anova(lm(y ~ x1+x2))
x1 <- c(1.01,2.01,3)
x2 <- c(1.01,2.01,3)
x3 <- c(-1,0,1)
x4 <- c(-1.01,0,1.01)
y <- c(-0.02,4,8.02)
summary(lm(y ~ x1+x2))
anova(lm(y ~ x1+x2))
summary(lm(y ~ x1+x2+x3+x4))
anova(lm(y ~ x1+x2+x3+x4))
x1 <- c(1.01,2.01,3)
x2 <- c(1.01,2.01,3)
x3 <- c(-1,0,1.01)
x4 <- c(-1.01,0,1)
y <- c(-0.02,4,8.02)
summary(lm(y ~ x1+x2+x3+x4))
anova(lm(y ~ x1+x2+x3+x4))
head(cars)
summary(lm(cars$dist ~ cars$speed))
cars[,7] <- c(10,11)
cars[7,] <- c(10,11)
summary(lm(cars$dist ~ cars$speed))
cars
view(cars)
View(cars)
summary(lm(cars$dist ~ cars$speed))
cars[51,] <- c(100,101)
summary(lm(cars$dist ~ cars$speed))
View(cars)
library(mlbench)
set.seed(234)
head(PimaIndiansDiabetes)
help(mlbench)
?mlbench
??mlbench
Pima.te
install.packages("mlbench")
install.packages("mlbench")
library(mlbench)
str(Pima.te)
str(Pima.tr)
str(Pima.tr2)
cvcontrol <- trainControl(method="repeatedcv",
number = 5,
repeats = 2,
allowParallel=TRUE)
forest <- train(Pima.te ~ .,
data=train,
method="rf",
trControl=cvcontrol,
importance=TRUE)
head(Pima.te)
x <- 1:10
r <- runif(10,0,1)/100
y <- exp(x+r)
summary(lm(y~x))
plot(x,y)
plot(lm(y~x))
x <- runif(100,0,1)
r <- runif(100,0,1)/100
y <- exp(x+r)
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,3)
r <- runif(100,0,1)/100
y <- exp(x+r)
summary(lm(y~x))
plot(x,y)
plot(lm(y~x))
r <- runif(100,0,1)/100
y <- exp(x+r)+r
summary(lm(y~x))
plot(x,y)
plot(lm(y~x))
x <- runif(100,0,5)
r <- runif(100,0,1)/100
y <- exp(x+r)+10*r
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,5)
r <- runif(100,0,1)/100
y <- exp(x+r)+100*r
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,5)
r <- runif(100,0,1)/100
y <- exp(x+r)+300*runif(100,0,1)/100
summary(lm(y~x))
plot(x,y)
plot(lm(y~x))
x <- runif(100,0,5)
y <- x+runif(1,0,x)
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,5)
y <- x+runif(1,-x,x)
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,5)
y <- x+runif(1,-x,x)^2
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,5)
y <- x+10*runif(1,-x,x)^2
summary(lm(y~x))
plot(x,y)
x <- runif(100,0,5)
y <- x+runif(1,min=-x,max=x)^2
summary(lm(y~x))
plot(x,y)
x <- 1:100
y <- x+runif(100,0,1:100)^2/100
summary(lm(y~x))
plot(x,y)
plot(lm(y~x))
plot(x,log(y))
plot(lm(log(y)~x))
library(ISLR)
set.seed(234)
head(Carseats)
forest <- train(data=Carseats, y=Sales)
forest <- train(Carseats, y=Sales, method="rf")
View(Carseats)
forest <- train(Carseats, y=Carseats$Sales, method="rf")
forest <- train(Carseats, y=Carseats$Sales, method="rf")
summary(forest)
forest <- train(Sales ~ ., data=Carseats, method="rf")
summary(forest)
library(randomForest)
forest <- randomForest(Sales ~ ., data=Carseats, importance=TRUE, proximity=TRUE)
summary(forest)
print(forest)
round(forest,5)
round(importance(forest),5)
round(importance(forest),2)
forest <- train(Sales ~ ., data=Carseats, method="rf", mtry=11)
forest <- train(Sales ~ ., data=Carseats, method="rf", mtry=11, importance=TRUE)
# forest <- train(Sales ~ ., data=Carseats, method="rf", mtry=11, importance=TRUE)
forest <- randomForest(Sales ~ ., data=Carseats, importance=TRUE, proximity=TRUE, mtry=11)
# forest <- train(Sales ~ ., data=Carseats, method="rf", mtry=11, importance=TRUE)
forest <- randomForest(Sales ~ ., data=Carseats, mtry=11)
# forest <- train(Sales ~ ., data=Carseats, method="rf", mtry=11, importance=TRUE)
forest <- randomForest(Sales ~ ., data=Carseats, mtry=10)
summary(forest)
print(forest)
forest
forest$mse
mean(sqrt(forest$mse))^2
mean(sqrt(forest$mse))
forest$rsq
